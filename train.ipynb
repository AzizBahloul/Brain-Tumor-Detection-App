{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, LearningRateScheduler, TensorBoard\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Check GPU availability\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Enable  mixed precision for better GPU performance\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = 'data/Testing'\n",
    "test_dir = 'data/Training'\n",
    "\n",
    "# Check if directories exist\n",
    "print(\"Trainingu Directory:\", os.path.exists(train_dir))\n",
    "print(\"Testing Directory:\", os.path.exists(test_dir))s\n",
    "\n",
    "# Image dimensions and batch size\n",
    "img_width, img_height = 224, 224\n",
    "batch_size = 32\n",
    "\n",
    "class TrainingVisualizer(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(TrainingVisualizer, self).__init__()e\n",
    "        self.epoch_times = []\n",
    "        self.training_logs = []\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_start_time = time.time()\n",
    "        print(f\"\\nEpoch {epoch + 1} starting...\")\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        self.epoch_times.append(epoch_time)\n",
    "        self.training_logs.append(logs)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        total_time = time.time() - self.start_time\n",
    "        avg_epoch_time = np.mean(self.epoch_times)\n",
    "        estimated_time_remaining = avg_epoch_time * (self.params['epochs'] - epoch - 1)\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{self.params['epochs']}\")\n",
    "        print(f\"Time taken for epoch: {epoch_time:.2f}s\")\n",
    "        print(f\"Average epoch time: {avg_epoch_time:.2f}s\")\n",
    "        print(f\"Total training time: {total_time/60:.2f}m\")\n",
    "        print(f\"Estimated time remaining: {estimated_time_remaining/60:.2f}m\")\n",
    "        \n",
    "        print(\"\\nMetrics:\")\n",
    "        print(f\"Loss: {logs['loss']:.4f}\")\n",
    "        print(f\"Accuracy: {logs['accuracy']:.4f}\")\n",
    "        print(f\"Validation Loss: {logs['val_loss']:.4f}\")\n",
    "        print(f\"Validation Accuracy: {logs['val_accuracy']:.4f}\")\n",
    "        \n",
    "        self.plot_progress(epoch)\n",
    "    \n",
    "    def plot_progress(self, epoch):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot([log['accuracy'] for log in self.training_logs], label='Training Accuracy')\n",
    "        plt.plot([log['val_accuracy'] for log in self.training_logs], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot([log['loss'] for log in self.training_logs], label='Training Loss')\n",
    "        plt.plot([log['val_loss'] for log in self.training_logs], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Create model\n",
    "print(\"Creating model...\")\n",
    "base_model = EfficientNetB7(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(img_width, img_height, 3)\n",
    ")\n",
    "\n",
    "# Unfreeze the top 20 layers\n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "print(\"Model created and compiled successfully!\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('model_output', exist_ok=True)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model_output/brain_tumor_modelv2.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "def cosine_decay(epoch, lr):\n",
    "    epochs = 20\n",
    "    alpha = 0.0\n",
    "    cosine_decay = 0.5 * (1 + np.cos(np.pi * epoch / epochs))\n",
    "    decayed_lr = (1 - alpha) * cosine_decay + alpha\n",
    "    return lr * decayed_lr\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(cosine_decay)\n",
    "tensorboard = TensorBoard(log_dir='model_output/logs', histogram_freq=1)\n",
    "visualizer = TrainingVisualizer()\n",
    "\n",
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=20,\n",
    "    callbacks=[checkpoint, reduce_lr, lr_scheduler, tensorboard, visualizer]\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "print(\"\\nEvaluating model...\")\n",
    "loss, accuracy, precision, recall = model.evaluate(test_generator)\n",
    "print(f'\\nFinal Metrics:')\n",
    "print(f'Loss: {loss:.4f}')\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Generate and print classification report\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(\n",
    "    test_generator.classes,\n",
    "    y_pred,\n",
    "    target_names=list(test_generator.class_indices.keys())\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
